{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_wikipedia_articles(article_titles):\n",
    "    with open('combined_articles.txt', 'w', encoding='utf-8') as f:\n",
    "        for article_title in article_titles:\n",
    "            article_url = f\"https://en.wikipedia.org/wiki/{article_title}\"\n",
    "            response = requests.get(article_url)\n",
    "            if response.status_code == 200:\n",
    "                soup = BeautifulSoup(response.content, 'html.parser')\n",
    "                article_text = ''\n",
    "                for paragraph in soup.find_all('p'):\n",
    "                    article_text += paragraph.text + ' '\n",
    "                f.write(article_text)\n",
    "                print(f\"Successfully downloaded article '{article_title}' to the combined file.\")\n",
    "            else:\n",
    "                print(f\"Failed to download article '{article_title}'. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded article 'China' to the combined file.\n",
      "Successfully downloaded article 'India' to the combined file.\n",
      "Successfully downloaded article 'United States' to the combined file.\n",
      "Successfully downloaded article 'Japan' to the combined file.\n",
      "Successfully downloaded article 'Russia' to the combined file.\n",
      "Successfully downloaded article 'United Kingdom' to the combined file.\n",
      "Successfully downloaded article 'Germany' to the combined file.\n",
      "Successfully downloaded article 'France' to the combined file.\n",
      "Successfully downloaded article 'Brazil' to the combined file.\n",
      "Successfully downloaded article 'Australia' to the combined file.\n",
      "Successfully downloaded article 'Italy' to the combined file.\n",
      "Successfully downloaded article 'Mexico' to the combined file.\n",
      "Successfully downloaded article 'Canada' to the combined file.\n",
      "Successfully downloaded article 'South Korea' to the combined file.\n",
      "Successfully downloaded article 'Indonesia' to the combined file.\n",
      "Successfully downloaded article 'Pakistan' to the combined file.\n",
      "Successfully downloaded article 'Nigeria' to the combined file.\n",
      "Successfully downloaded article 'Egypt' to the combined file.\n",
      "Successfully downloaded article 'Turkey' to the combined file.\n",
      "Successfully downloaded article 'Iran' to the combined file.\n",
      "Successfully downloaded article 'Saudi Arabia' to the combined file.\n"
     ]
    }
   ],
   "source": [
    "article_titles = [\n",
    "    \"China\",\n",
    "    \"India\",\n",
    "    \"United States\",\n",
    "    \"Japan\",\n",
    "    \"Russia\",\n",
    "    \"United Kingdom\",\n",
    "    \"Germany\",\n",
    "    \"France\",\n",
    "    \"Brazil\",\n",
    "    \"Australia\",\n",
    "    \"Italy\",\n",
    "    \"Mexico\",\n",
    "    \"Canada\",\n",
    "    \"South Korea\",\n",
    "    \"Indonesia\",\n",
    "    \"Pakistan\",\n",
    "    \"Nigeria\",\n",
    "    \"Egypt\",\n",
    "    \"Turkey\",\n",
    "    \"Iran\",\n",
    "    \"Saudi Arabia\"\n",
    "]\n",
    "\n",
    "download_wikipedia_articles(article_titles)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
